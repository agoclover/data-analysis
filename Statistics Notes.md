# 统计学概述

在概率论中，我们多研究的随机变量，它的分布都是假设已知的。如果你已经知道了随机变量X是的分布和参数，你去推导它的期望、方差等数字特征，去推导它其他一些性质，去推导X的平方是什么分布，或推导和另一个随机变量Y相加又是什么分布。这些工作属于**概率论**范畴。

但在数理统计中，我们研究的随机变量，它的分布是未知的，或者是某些参数不知道，人们通过对所研究的随机变量进行重复独立的观察，得到许多观察值，对这些数据进行分析，从而对所研究的随机变量的分布做出种种推断。比如，实际工作中有个随机变量Z，你不知道是什么分布，你看到了一些试验值，觉得Z可能是正态分布，于是你假设Z是正态分布，你用试验数据，推断出它的均值可能是1，方差可能是4，然后做假设检验，看看这一结论在多大程度上可靠，如果认为可靠，用这个结论来做分析，或者预测将要进行的试验结果。这叫**统计**。

概率论是统计推断的基础，在给定数据生成过程下观测、研究数据的性质，是**推理**；而统计推断则根据观测的数据，反向思考其数据生成过程。预测、分类、聚类、估计等，都是统计推断的特殊形式，强调对于数据生成过程的研究，是**归纳**。

本文中示例以==高亮==标出。

# 概率论

### 随机试验

**随机试验**是[概率论](https://zh.wikipedia.org/wiki/概率论)的一个基本概念。 概括地讲，在[概率论](https://zh.wikipedia.org/wiki/概率论)中把符合下面三个特点的试验叫做随机试验：

1. 可以在相同的条件下重复的进行。
2. 每次试验的可能结果不止一个，并且能事先明确试验的所有可能结果。
3. 进行一次试验之前不能确定哪一个结果会出现。

随机试验通常用*E*（event）表示：

==*E*：抛1颗骰子，观察出现的点数情况。==

### 样本空间

随机试验E的所有可能结果组成的集合成为E的**样本空间**，记为S。

样本空间的元素，即E的每个结果，成为**样本点**。

==*S* = {点1, 点2, 点3, 点4, 点5, 点6}==

==点1~点6均为样本点。==

### 随机事件

随机试验E的样本空间S的子集为E的**随机事件**，在每次试验中，当且仅当这一子集中的一个样本点出现时，称这一**事件发生**。由一个样本点组成的单点集，成为**基本事件**。S本身成为**必然事件**。∅不包含任何样本点，成为**不可能事件**。

==A~1~：抛1颗骰子，出现的点数大于3==

### 随机变量

设随机试验的样本空间为$S=\left\{ e \right\} $，$ X=X\left( e \right) $是定义在样本空间上的实值单值函数，则称$X$为随机变量。一般以大写字母X，Y，Z等表示随机变量，而以小写字母x，y，z等表示实数。随机变量的取值随试验的结果而定，在试验之前不能预知取值，且它的取值有一定的概率。

随机变量有**离散型**和**连续型**：

离散型随机变量有其**分布律**；

连续型随机变量可以满足一定**分布**。

==X为点数对应的数字：X=1, 2, 3, 4, 5, 6，离散型==

==A1：X>3==

==$P\left( X>3 \right) =\frac { 1 }{ 2 } $==

### 离散型随机变量分布律

#### 0-1分布

####二项分布

#### 几何分布

#### 超几何分布

#### 泊松分布

### 连续型随机变量的分布

分布函数、概率密度函数、随机变量的函数的分布

#### 均匀分布

#### 指数分布

#### 正态分布

### 随机变量数字特征

#### 期望

#### 方差

#### 标准差

#### 协方差

#### 相关系数

#### 矩和协方差矩阵

### 大数定律

### 中心极限定理

# 抽样、整理、抽样分布

## 抽样：总体与样本

### 总体

**总体**，是指由许多有某种共同性质的事物组成的集合，会在此集合中选出样本进行[统计推断](https://zh.wikipedia.org/wiki/统计推断)，选取样本的方式可能会用乱数或是其他[抽样](https://zh.wikipedia.org/wiki/抽樣)方式。

例如要针对所有乌鸦的共有特性进行研究，总体是目前存在、以前曾经存在或是未来可能存在的所有乌鸦。**但是，因为时间的限制、地域可取得性的限制、以及研究者的有限资源等，不可能观测总体中的每一个，因此研究者会从总体中产生样本，再由样本的特性去了解总体的特性。**

产生样本的目的之一就是为了要知道**总体的特性**，包括

- 总体均值：$\mu =\frac { \sum _{ i=1 }^{ N }{ { x }_{ i } }  }{ N } $
- 总体标准差：$\sigma =\sqrt { \frac { 1 }{ N } \sum _{ i=1 }^{ N }{ { \left( { x }_{ i }-\mu  \right)  }^{ 2 } }  } $

### 样本

研究中，从总体中抽取（观察或调查）一部分的个体称为样本。

#### 样本容量

样本容量是指一个样本中所包含的单位数，一般用n表示，它是抽样推断中非常重要的概念。样本容量的大小与推断估计的准确性有着直接的联系，即在总体既定的情况下，样本容量越大其统计估计量的代表性误差就越小，反之,样本容量越小其估计误差也就越大。

#### 样本均值

根据样本构造的不含未知参数的函数为**统计量**，样本均值是一个统计量。我们可以用样本均值描述一个样本，多个样本则会有多个样本均值。

## 整理：统计数据的整理和显示

### 直方图和箱线图

#### 直方图

略

#### 分位

##### Q1：四分位

##### Q3：四分之三分位

##### IQR：四分位差

1. 几乎 50% 的数据在 IQR 间。
2. IQR 受到数据集中每一个值的影响。
3. IQR 不受异常值的影响。
4. 均值不一定在IQR中；

#### 异常值Outlier

Outlier < Q1 - 1.5 * IQR

Outlier > Q3 + 1.5 * IQR

#### 箱线图Boxplot

![箱线图图示](/Users/amos/Desktop/Data%20Analysis/%E7%AE%B1%E7%BA%BF%E5%9B%BE%E5%9B%BE%E7%A4%BA.jpg)

### 集中趋势

#### 均值Mean

当数据中出现异常值时，均值无法描述分布中心；

#### 中位数Medium

众数也很难描述分布中心；

#### 众数Mode

中位数不会考虑到所有的数据，对异常值的鲁棒性更好。在处理高偏斜分布时，中位数通常能够最好地反映出集中趋势。

#### 正偏斜分布与负斜分布

正斜分布靠左：mode<medium<mean

负斜分布靠右：mean<medium<mode

#### 鲁棒性Robust

即使偏离了基准也不会受太大的影响。

### 离散程度

#### 方法

找出任意两个值之间差的平均值：数值过多

找出每个值与最大值或最小值之间差的平均值：容易受异常值干扰

找出每个值与数据集均值之间差的平均值：适合

#### 概念

**离均差**：${ x }_{ i }-\bar { x } $

**平均偏差**：$\sum { \frac { { x }_{ i }-\bar { x }  }{ n }  }=0 $

**平均绝对偏差**：$\sum { \frac { \left| { x }_{ i }-\bar { x }  \right|  }{ n }  } =0$

**（总体）方差(平均平方偏差**)：$DX=\sum { \frac { { \left( { x }_{ i }-\bar { x }  \right)  }^{ 2 } }{ n }  } =E{ \left( X-EX \right)  }^{ 2 }=E{ X }^{ 2 }-{ \left( EX \right)  }^{ 2 }$

**（总体）标准差**：$\sigma =\sqrt { DX } $

#### 贝塞尔校正

比如在高斯分布（正态分布）中，我们抽取一部分的样本，用样本的方差来估计总体的方差。由于样本主要是落在x=μ中心值附近，那么样本方差一定小于总体的方差（因为高斯分布的边沿抽取的数据很少）。为了能弥补这方面的缺陷，那么我们把公式的n改为n-1,以此来提高方差的数值。这种方法叫做贝塞尔校正系数。

当我们用小样本数据的标准差去估计总体的标准差的时候采用 n-1,但是这个小样本数据的实际标准差还是用 n 的那个公式 的，不要混淆了数据的实际标准差。

#### 无偏性证明

对于一个随机变量$X$进行$n$次抽样，获得样本${ x }_{ 1 },{ x }_{ 2 },...,{ x }_{ n }$，那么样本均值为:$\bar { x } =\frac { 1 }{ n } \sum _{ i=1 }^{ n }{ { x }_{ i } } $

有偏的样本方差为:

![equation](/Users/amos/Desktop/Data Analysis/equation-6992567.svg)

无偏的样本方差为：

![equation](/Users/amos/Desktop/Data Analysis/equation.svg)

为了证明![s^{2}](https://www.zhihu.com/equation?tex=s%5E%7B2%7D)的无偏性， 我们拿出样本方差种的一部分来进行单独分析,

![equation](/Users/amos/Desktop/Data Analysis/equation-6992606.svg)

同理，我们有

![equation](/Users/amos/Desktop/Data Analysis/equation-6992634.svg)

对上式两侧取期望，我们有

![equation](/Users/amos/Desktop/Data Analysis/equation-6992660.svg)

因为![\overline{x}=\frac{1}{n}\sum_{i=1}^n x_i](https://www.zhihu.com/equation?tex=%5Coverline%7Bx%7D%3D%5Cfrac%7B1%7D%7Bn%7D%5Csum_%7Bi%3D1%7D%5En+x_i)，于是我们有![\begin{align*} \operatorname{Var}{(\overline {x})} = \frac{1}{n}\operatorname{Var}{{x}} \end{align*}](https://www.zhihu.com/equation?tex=%5Cbegin%7Balign%2A%7D+%5Coperatorname%7BVar%7D%7B%28%5Coverline+%7Bx%7D%29%7D+%3D+%5Cfrac%7B1%7D%7Bn%7D%5Coperatorname%7BVar%7D%7B%7Bx%7D%7D+%5Cend%7Balign%2A%7D)

因此

![equation](/Users/amos/Desktop/Data Analysis/equation-6992686.svg)

最后，我们有

![equation](/Users/amos/Desktop/Data Analysis/equation-6992748.svg)

可见${ S }^{ 2 }$是对$Var\left( X \right)$ 的无偏估计。

#### 3σ原则

数值分布在（μ-σ,μ+σ)中的概率为0.6827

数值分布在（μ-2σ,μ+2σ)中的概率为0.9545

数值分布在（μ-3σ,μ+3σ)中的概率为0.9973

### 归一化：标准正态分布

**样本均值的频数直方图**的数字不能直接看出比例排名，所以引入**频率直方图**，但直方图固有弊端在于会缺少部分信息，所以需要缩小组距以增加信息，但过小又没有了直方图意义，所以引入**概率分布图**——**标准正态分布**。

#### Z 值：标准差数量

##### 公式

$z=\frac { x-\mu  }{ \delta  } $

##### 含义

无论值是多少，我们都可以将其转换为与均值的标准差。通过将正态分布中的值转换为z，就可以知道小于或大于该值得百分比。

例如某个值与平均值相差1个标准偏差σ，则无论是哪种正态分布，我们都知道大约80%的值<该值。

#### 标准正态分布

我们可以将任何正态分布转化为标准正态分布，通过Z值进行分析，再按照任何方式扩展。

#### Z 值表

[链接](https://s3.amazonaws.com/udacity-hosted-downloads/ZTable.jpg)。

## 抽样分布

### 样本统计量

根据样本构造的不含未知参数的函数为统计量。

#### 样本均值

#### 样本方差

#### 样本标准差

#### 样本K阶(原点)矩

#### 样本K阶中心矩

### 抽样分布

在使用统计量进行统计推断时，需要知道统计量的分布，比如样本均值的分布。

**统计量的分布**，叫做**抽样分布**。总体分布函数已知时，样本分布是确定的，但是：

1. 通常，我们是不知道总体分布的；
2. 要求出统计量的精确分布是困难的。

虽然总体不知道时，我们很难确定，解决这种问题需要学习非参数统计。然而，有两种情况是比较好研究的：

1. 对于正太总体分布，其常用的统计量的分布是可以推断出来的。
2. 对于一般总体分布，我们可以由大数定律和中心极限定理得到其样本均值统计量的期望、分布和方差等。

### 正态总体的常用统计量的分布

#### 样本均值与样本方差

1. 如果给出某个随机样本，我们算出它的均值。通过**样本均值分布的标准偏差**可以判断该均值位于这一**样本均值分布**的位置。
2. 样本均值分布的均值=总体均值。
3. 样本均值分布的方差=总体方差/n

#### 卡方分布

#### t分布

#### F分布

### 一般总体样本均值的分布

#### 大数定律和中心极限定理回顾

在概率论中，我们已经了解了**大数定律**和**中心极限定理**（详见前面的章节）：

**大数定律**讲的是样本均值收敛到总体均值（就是期望），像这个图一样：

![v2-5dcd7a13095ba29c6a5c8717d83a5ff5_hd](/Users/amos/Desktop/Data Analysis/v2-5dcd7a13095ba29c6a5c8717d83a5ff5_hd.jpg)

而中心极限定理告诉我们，当样本量足够大时，样本均值的分布慢慢变成正态分布，就像这个图：

![v2-8755dc22a65c4ef475cc391f9302161d_hd](/Users/amos/Desktop/Data Analysis/v2-8755dc22a65c4ef475cc391f9302161d_hd.jpg)

#### 示例

X代表掷骰子点数的随机变量，X=1,2,…,6，EX=3.5，我们做一次试验时掷2次骰子，即样本容量为2，做一次实验的话是一个样本，2个数字的均值是一个统计量，叫样本均值。

对于这个实验，我们知道总体分布或分布律，为比如一个样本(1, 4)，样本均值=2.5，也就是观察值=2.5。我们可以发现，只做一次试验，样本统计量的观察值是不等于总体X的均值EX=3.5的。

但是，只要我们试验的次数足够多，比如又做了100次试验，得到100个样本：(4, 6), (3, 1), (1, 2)… 样本均值的观察值依次为：5，2，1.5，… 大数定律说的就是这些样本均值依概率收敛于总体期望，即$\frac { 1 }{ 100 } \left( 2.5+5+2+1.5... \right) \approx 3.5=EX$ ，用依概率收敛的符号表示即$\bar { { X }_{ n } } \xrightarrow [  ]{ p } \mu $。

中心极限定理是说，当样本量足够大时，这些样本均值的观察值是满足正态分布的。

#### 总结

随机变量$X$，$EX=\mu $，$DX={ \sigma  }^{ 2 }$。则独立同分布情况下，若样本量很大，由中心极限定理，样本均值$\bar { X } $近似地服从参数为$N(\mu ,\frac { { \sigma  }^{ 2 } }{ n } )$的正态分布。

样本容量如果增大n倍，其标准差会缩小为$\frac { 1 }{ \sqrt { n }  } $，分布也会变窄。

#### 应用

1. 对于一个随机变量$X$，$EX=\mu $，$DX={ \sigma  }^{ 2 }$。若设定样本容量为n，我们可以得到样本均值$\bar { X } $的满足参数为$N(\mu ,\frac { { \sigma  }^{ 2 } }{ n } )$的正态分布，换个说法，$\frac { \bar { X } -\mu  }{ { \sigma  }/{ \sqrt { n }  } } \sim N\left( 0,1 \right) $.

2. 在分布确定、有了抽样分布的基础上，当我们实际得到一个样本，我们想检验这个样本是否正常。
3. 既然μ，σ和n均已知，那么$\frac { \bar { X } -\mu  }{ { \sigma  }/{ \sqrt { n }  } } $是一个统计量，即z，由于单位正态分布天然的计算和观察优势，我们可以利用z得到出现此样本的概率。
4. 比如，我们得到z>z~0~的概率只有0.01，那么我们可以认为这是不正常的。因为小概率事件在一次试验中是很难发生的，但也确实有可能发生，比如这里发生的几率就是0.01。
5. 所以我们如果假定，一次试验当原假设为真时，我们不接受它的概率为0.05，也就是说弃真错误α=0.05，我们就会抛弃这个样本，觉得它是假的，也就是说我们认为这个样本不正常。另一种说法是，我们有0.95的把握认为这个样本是不正常的。
6. 这就是假设检验的基本思想，具体会在之后的章节提到。

# 参数估计

# 假设检验

# 方差分析

# 非参数估计

# 时间序列分析

# 多元统计分析